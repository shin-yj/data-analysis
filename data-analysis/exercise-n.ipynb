{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, NavigableString, Tag, Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = \"https://news.naver.com/main/list.nhn\"\n",
    "query = \"mode={0}&mid={1}&sid2={2}&sid1={3}&date={4}&page={5}\"\n",
    "\n",
    "page = 1\n",
    "date = '20200702'\n",
    "\n",
    "news_list = []\n",
    "\n",
    "if True:\n",
    "    current_url =\"\".join([url, \"?\", query]).format(\"LS2D\", \"shm\", \"230\", \"105\", date, page)\n",
    "    current_url\n",
    "\n",
    "# print(current_url)\n",
    "\n",
    "resp = requests.get(current_url)\n",
    "soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "# print(soup)\n",
    "\n",
    "dl_list = soup.select(\"#main_content .list_body > ul > li > dl\")\n",
    "\n",
    "if len(dl_list) == 0:\n",
    "    pass\n",
    "\n",
    "for idx, dl in enumerate(dl_list):\n",
    "    links = dl.select('dt > a')\n",
    "    link = links[0] if len(links) == 1 else links[1]\n",
    "    news_list.append([link.text.strip(), link['href']]) # strip() => 공백 제거\n",
    "\n",
    "# news_list[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for news in news_list:\n",
    "    \n",
    "    time.sleep(0.3)\n",
    "\n",
    "    link2 = news[1]\n",
    "    resp2 = requests.get(link2)\n",
    "    soup2 = BeautifulSoup(resp2.text, 'html.parser')\n",
    "    \n",
    "    contents = soup2.select_one('div#articleBodyContents')\n",
    "    content_string = \"\"\n",
    "    for child in contents.children:\n",
    "        # print(child, '/', type(child))\n",
    "        if type(child) == Tag and child.name != \"script\":\n",
    "            content_string += child.text.strip() + \" \"\n",
    "        if type(child) == NavigableString:\n",
    "            content_string += str(child).strip() + \" \"\n",
    "    \n",
    "    # print(content_string)\n",
    "    news.append(content_string) # [제목, 주소] -> [제목, 주소, 내용]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_list[:3]\n",
    "news_list_df = pd.DataFrame(news_list, columns=['제목', '링크', '내용'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_list_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python361064bithoseoconda78849c8c42504bfc91e9e5131e728d2c",
   "display_name": "Python 3.6.10 64-bit ('hoseo': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}